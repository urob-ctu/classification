from typing import Dict

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

from assignments.knn_classifier import KNNClassifier


def cross_validate_knn(classifier: KNNClassifier, X: np.ndarray, y: np.ndarray,
                       k_choices: np.ndarray, num_folds: int) -> Dict[str, Dict[int, np.ndarray]]:
    """Performs cross-validation for kNN classifier. This is done by following the steps below:
        1. Randomly shuffle the data and labels.
        2. Split the data into k_folds.
        3. For each k in k_choices:
            3.1. For each fold:
                3.1.1. Train the classifier on the training data.
                3.1.2. Predict labels for the validation data.
            3.2. Compute the metrics for the current k.
        4. Return the metrics for all k.

    Args:
        classifier (KNNClassifier): The kNN classifier to be cross-validated.
        X (numpy.ndarray): The training data features of shape (N, D), where N is the number of data points and D is
            the number of features.
        y (numpy.ndarray): The training data labels of shape (N,).
        k_choices (numpy.ndarray): An array of k values.
        num_folds (int): The number of folds to be used for cross-validation.

    Returns:
        dict: A dictionary containing the results of cross-validation. The keys are the names of the metrics and the
            values are dictionaries containing the metric values for different values of k. The resulting values should
            be mean values over all folds.

            Metrics:
                - accuracy: The accuracy of the classifier computed by `sklearn.metrics.accuracy_score()`.
                    The value for each k is a scalar.
                - precision: The precision of the classifier computed by `sklearn.metrics.precision_score()`.
                    The value for each k is a numpy array of shape (num_classes).
                - recall: The recall of the classifier computed by `sklearn.metrics.recall_score()`.
                    The value for each k is a numpy array of shape (num_classes).
                - f1: The f1 score of the classifier computed by `sklearn.metrics.f1_score()`.
                    The value for each k is a numpy array of shape (num_classes).

            Important: The precision, recall, and f1 metrics are computed for each class separately, you should use
                `sklearn.metrics.precision_score(..., average=None)` to compute the metrics for each class.

            Example: If we have 3 classes and 4 folds and k_choices = [1, 3, 5, 7], then the dictionary returned
                by this function will be:

            k_to_metrics = {
                'accuracy': {
                    1: 0.9,
                    3: 0.1,
                    5: 0.5,
                    7: 0.1
                },
                'precision': {
                    1: [0.9, 0.8, 0.7],
                    3: [0.1, 0.3, 0.6],
                    5: [0.5, 0.2, 0.3],
                    7: [0.1, 0.1, 0.8]
                },
                'recall': {
                    1: [0.6, 0.5, 0.4],
                    ...
                },
                'f1': {
                    1: [0.8, 0.7, 0.6],
                    ...
                }
            }
    """
    k_to_metrics = dict()
    k_to_metrics["accuracy"] = dict()
    k_to_metrics["precision"] = dict()
    k_to_metrics["recall"] = dict()
    k_to_metrics["f1"] = dict()

    # ‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ± Assignment 2.2 ‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞ #
    # TODO:                                                             #
    # Implement cross-validation for kNN classifier. Use ChatGPT to     #
    # understand the k-fold cross-validation procedure. You may use     #
    # ChatGPT to generate the code for this function.                   #
    #                                                                   #
    # HINT: You may find the following functions useful:                #
    #      - np.random.shuffle                                          #
    #      - np.array_split                                             #
    #      - sklearn.metrics.accuracy_score                             #
    #      - sklearn.metrics.precision_score                            #
    #      - sklearn.metrics.recall_score                               #
    #      - sklearn.metrics.f1_score                                   #
    #                                                                   #
    # Good luck!                                                        #
    # ‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞‚ñ±‚ñ∞ #
    # üåÄ INCEPTION üåÄ (Your code begins its journey here. üöÄ Do not delete this line.)

    # Randomly shuffle data and labels
    indices = np.arange(X.shape[0])
    np.random.shuffle(indices)
    X, y = X[indices], y[indices]

    # Split data into 5 folds
    data_folds = np.array_split(X, num_folds)
    label_folds = np.array_split(y, num_folds)

    for k in k_choices:
        accuracies, precisions, recalls, f1s = [], [], [], []
        classifier.k = k
        for i in range(num_folds):
            X_train = np.concatenate(data_folds[:i] + data_folds[i + 1:])
            y_train = np.concatenate(label_folds[:i] + label_folds[i + 1:])
            X_val = data_folds[i]
            y_val = label_folds[i]

            classifier.train(X_train, y_train)
            y_pred = classifier.predict(X_val)
            accuracies.append(accuracy_score(y_val, y_pred, normalize=True))
            precisions.append(precision_score(y_val, y_pred, average=None))
            recalls.append(recall_score(y_val, y_pred, average=None))
            f1s.append(f1_score(y_val, y_pred, average=None))

        precisions = np.vstack(precisions)
        recalls = np.vstack(recalls)
        f1s = np.vstack(f1s)

        k_to_metrics['accuracy'][k] = np.mean(accuracies)
        k_to_metrics['precision'][k] = np.mean(precisions, axis=0)
        k_to_metrics['recall'][k] = np.mean(recalls, axis=0)
        k_to_metrics['f1'][k] = np.mean(f1s, axis=0)

    # üåÄ TERMINATION üåÄ (Your code reaches its end. üèÅ Do not delete this line.)

    return k_to_metrics
